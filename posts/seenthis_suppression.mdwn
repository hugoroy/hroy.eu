[[!tag lang:fr]]
[[!meta title="Droit à l’oubli et liberté d’expression"]]

Une discussion intéressante a été lancée [sur seenthis]. Elle est
difficile à résumer rapidement, mais voici le problème :

Que faire lorsqu’un utilisateur désire supprimer un
message qu’il a posté ?

Ce problème se pose pour toute sorte de communication, et la
réponse appropriée à apporter varie probablement selon le type de
message posté et le genre de media utilisé.

Il se pose parfois sous d’autres formes :

  - faut-il instaurer un [[!taglink droit_à_l’oubli|right_to_be_forgotten]] ?

  - la [[!taglink censure|censorship]] est-elle parfois légitime ou autrement dit, dans
    quelle mesure admet-on qu’il y a abus de la liberté
    d’expression ?

  - à partir du moment où une information est publique, est-il
    normal de pouvoir la réutiliser à toutes les sauces ?

    Il n’y a probablement pas de réponse simple, tout n’est pas
    complètement blanc ou noir, par exemple un projet comme
    <http://useraddress.net/> me semble assez différent d’un
    truc aussi immonde que [123people].

[sur seenthis]: http://seenthis.net/messages/199925
[123people]: https://en.wikipedia.org/wiki/123people

Bref, tout ça pour dire que nous sommes là face à un problème
épineux et qu’il n’y a certainement pas de réponse toute-faite. Je
voudrais en revanche explorer quelques enjeux soulevés par la
discussion.

Imaginons une discussion passionnée avec des gens très opiniâtres,
appelons-les Alice et Bob pour faire original, sur un sujet
trollesque. Celle-ci a lieu sur une liste de diffusion par email,
semi-publique, c’est-à-dire que les archives sont disponibles pour
les membres de la liste uniquement, mais chacun peut rejoindre la
liste librement et obtenir l’accès à l’intégralité des archives.

De toute évidence, la façon dont la liste de diffusion est
configurée par défaut est déjà en-soi très déterminant. Par
exemple, si la participation a la liste est soumise à des règles
spéciales, il faudrait probablement que les choix techniques soit
en adéquation avec ces règles. (Par exemple, les [discussions
juridiques hébergées][ftf-legal] par la FSFE sont soumises à la
[règle de Chatham House], il aurait été idiot de confier les
archives à Mailman).

[ftf-legal]: https://fsfe.org/activities/ftf/network.html
[règle de Chatham House]: https://fr.wikipedia.org/wiki/R%C3%A8gle_de_Chatham_House

Faisons un bond en avant de 10 ans. Alice regrette profondément
d’avoir tenu de tels propos à l’époque, ceux-ci lui causent un
tort particulier. Non seulement Alice a changé d’avis (on a bien
le droit après tout !) mais en plus le fait que cette discussion
ait été rendue publique par Charlie, administrateur de la liste
ayant changé les règles d’accès aux archives, fait que le nom
d’Alice remonte systématiquement en étant associé aux recherches
sur Google concernant ce sujet.

De son côté, Bob n’a pas changé d’avis et il reste toujours très
content de ses arguments, d’autant plus qu’ils se sont avérés
assez efficaces pour persuader : beaucoup de gens qui relisent la
discussion a posteriori sont convaincus qu’il a raison.

On voit bien dans ce cas que, du point de vue d’Alice, un droit à
l’oubli serait bénéfique. Il est assez injuste de la tenir
responsable de propos tenus il y a dix ans, non seulement elle a
droit de changer d’avis, mais en plus Alice a échangé ces propos
sur une liste semi-publique à l’époque.

Du point de vue de Charlie, la décision de rendre les archives
publiques a été motivée par de multiples facteurs, d’autant plus
que la liste de diffusion en question a évolué et est devenue
tellement plus grande qu’en restreindre l’accès n’avait plus
beaucoup de sens. Reste que sa décision, dans le cas exceptionnel
d’Alice cause un tort à celle-ci.

On pourrait mettre Alice et Charlie d’accord probablement en
supprimant les propos d’Alice.

Mais voilà qui ne plairait pas beaucoup à Bob, puisque sans les
messages d’Alice, les propos qu’il a tenus perdraient beaucoup de
leur sens. On peut ajouter que les perdants dans cette histoire
sont aussi tous les futurs lecteurs potentiels qui pourraient
trouver un intérêt quelconque (curiosité, recherche historique,
sociologique, politique, que sais-je…).


J’espère qu’à partir de ce moment, il est clair qu’il n’y a pas de
solution forcément plus juste que les autres. En tout cas,
j’aimerais maintenant aborder un argument qu’on retrouve dans ces
discussions, et qui, à mon point de vue, est plutôt mauvais.

* * *

Beaucoup d’utilisateurs
prennent la position d’Alice et réclament en quelque sorte un
droit sur les propos tenus. De quelle sorte de droit il s’agit en
réalité, il est difficile de le cerner. 

Ces arguments se retrouvent notamment dans la discussion sur
seenthis : ces propos appartiendraient à l’auteur, et par
conséquent celui-ci aurait une sorte de droit de les voir
supprimés réellement. 

Malheureusement, cette position ne permet de répondre à aucun des
problèmes d’ordre plus collectif et en plus, cette position ne
résout pas vraiment la situation individuelle d’Alice :

  - si on prend le problème d’un point de vue plus collectif
    qu’individuel, on voit bien que cet argument ne tient pas. En
    effet, admettons que les propos d’Alice lui « appartiennent »,
    alors dans ce cas, les propos tenus par Bob lui
    appartiendraient également. Or dans la discussion,
    typiquement, les propos tenus par l’un et par l’autre sont
    indissociables. 

    Quant au contexte plus large, il est important pour le public.
    On voit bien que donner un pouvoir arbitraire à Alice de
    retirer ses propos aurait pour conséquence de retirer à Bob le
    sens de ses propos. Sauf à démontrer un besoin impérieux de
    faire primer le préjudice d’Alice sur celui de Bob et sur
    celui du public en général, cette position n’est pas
    satisfaisante.

    En vérité, Alice n’a pas de droit de propriété sur ses propos,
    mais elle a la liberté de s’exprimer au même titre que Bob. La
    liberté de chacun consiste dans ce qui ne nuit pas à autrui.
    On voit donc qu’accorder un pouvoir arbitraire de suppression
    de ses propos à Alice revient à lui accorder une prérogative
    injuste pour Bob, un véritable pouvoir de censure.

  - d’autre part cette solution ne résout pas réellement le
    problème puisque s’il y a un intérêt quelconque dans les
    propos en cause, alors il est probable que de vouloir les
    retirer aura davantage pour conséquence de déclencher
    mécontentements et [effet Streisand], que l’inverse.

  - Enfin cette solution nécessite le concours de Charlie qui
    administre la liste, et en tant que tel reste maître des
    lieux. Mais en plus selon l’architecture technique choisie la
    solution peut s’avérer assez inutile (par exemple si la liste
    est archivée par un tiers, ou si l’archivage a été distribué :
    dans notre exemple, chaque participant à la liste de diffusion
    en a une copie dans sa boîte email et pourra probablement la
    re-publier ailleurs).

[effet Streisand]: https://fr.wikipedia.org/wiki/Effet_Streisand

* * *

On voit bien qu’accorder une sorte de droit arbitraire à chaque
utilisateur de pouvoir faire détruire ses propos enregistrés et
publiés par un moyen qu’il ne contrôle pas totalement n’apparaît
pas comme la solution idéale. C’est pourtant plus ou moins la
solution mise en place sur Twitter par exemple. Je peux revenir
dans le temps et supprimer n’importe quel tweet, avec toutes les
conséquences que cela peut avoir sur les personnes qui auraient
ensuite répondu. On voit d’ailleurs que les problèmes soulevés
plus haut se présentent.

Si quelqu’un tente de supprimer une énorme connerie raciste qu’il
vient d’écrire, il est probable que certains auront pris des
screenshots au cas où.

D’autre part, même si on supprime, Twitter ne va pas réellement
supprimer le tweet (de même que Facebook, YouTube et
d’innombrables autres services, c’est souvent marqué noir sur
blanc dans leurs [CGU] que ce qui est « supprimé » n’est en
réalité pas vraiment supprimé…)

Enfin, selon les paramètres de chaque utilisateur sur Twitter, il
est possible que Twitter ait envoyé par email une copie du tweet
lorsque celui-ci était partagé, il sera impossible de supprimer
cela.

[CGU]: https://fr.wikipedia.org/wiki/Conditions_g%C3%A9n%C3%A9rales_d%27utilisation

* * *

On peut se dire à ce stade que sur Twitter ce n’est pas bien grave
après tout puisqu’un seul tweet en lui-même n’étant que 140
caractères, il n’y a pas énormément de perte.

Évidemment, sur un service plus complet comme seenthis, ça pose un
problème.

* * *

Alors que faire ?

Moi ce qui m’embête, c’est qu’il est devenu très très facile de
publier et de communiquer grâce au Web. Et donc la liberté
d’expression prend une toute autre dimension. Disons que si je
publie un truc par an, je prendrais probablement beaucoup de temps
de réflexion pour peaufiner ce que je publie, peser le pour et le
contre, etc. Dans cette optique, lorsque je fais usage de ma
liberté d’expression, il est normal que j’assume le propos que
j’ai publié à un moment donné. Mais dans l’optique où on publie
beaucoup et tous les jours, il me semble normal d’envisager qu’il
n’est pas très juste d’imposer une telle responsabilité. Après
tout, on a non seulement le droit de changer d’avis, mais on a
aussi un peu le droit de dire des bêtises de temps en temps sans
qu’on n’en tienne forcément rigueur.

Bref, il peut être tout à fait légitime qu’on décide de faire
quelque chose pour la pauvre Alice, qui n’a pas vraiment envie
d’assumer des propos qui ont pris une toute autre mesure qu’elle.
D’ailleurs, le fait que ce soit Alice qui les ait publiés n’est
pas forcément important en soi ! C’est donc que décider de ne pas
supprimer les propos en cause, lui cause un tort qui n’est
nullement nécessaire. (Si le fait que ce soit Alice qui ait tenus
de tels propos est si important, par exemple si Alice est une
personnalité publique importante sur le sujet, elle aurait dû
mieux savoir et donc, à elle d’assumer… mais ce n’est pas le cas
typique.)

C’est pourquoi je trouve qu’on peut envisager d’autres solutions,
à mettre en place techniquement, et qui permettraient de mettre à
peu près tout le monde d’accord dans la majorité des cas.

Puisque le tort causé à Alice réside davantage dans l’association
qu’on fait du propos à sa personne, il suffit de couper ce lien
entre le propos, et elle-même. Par exemple, si Alice avait publié
cela il y a dix ans sous un pseudonyme  qu’elle n’utiliserait
plus, alors le problème ne se poserait même pas. Dans cette
hypothèse, il semble tout à fait opportun d’opérer une
[[!taglink anonymisation]] des propos en question. De cette manière, ils ne
sont plus associés à Alice, d’autre part les propos de Bob ne
perdent pas leur sens, et enfin il reste assez de matière pour que
tout le monde soit content et puisse exploiter tout ce que le
contenu a d’intéressant à offrir.

On peut aussi imaginer de faire une sorte de relégation des propos
si cela s’avère justifié. Par exemple, on pourrait appliquer une
sorte de « tag » indiquant que le message n’est plus approuvé par
son auteur, on pourrait entre autres décider d’exclure le
message des moteurs de recherche publics. Pour certains, cette
solution est problématique car elle « tromperait » Alice. Si Alice
croit qu’elle « supprime » son message, il faut qu’elle ait
l’impression que ce soit fait, sinon Charlie a peur de perdre la
confiance de ses utilisateurs.

Mais c’est un faux problème. D’une part, il suffirait de mieux
présenter la fonctionnalité pour éviter tout malentendu et
expliquer à Alice que, son propos a été publié et qu’il ne peut
donc pas être supprimé sinon ce serait de la censure arbitraire,
de cette manière celle-ci n’aurait pas l’impression d’être trompée
si le message n’a pas été supprimé ; d’autre part, en réalité
beaucoup de services ne suppriment pas réellement les messages (ou
en tout cas ils ne peuvent pas les supprimer partout), donc c’est
un argument un peu fallacieux.

* * *

La solution que je propose est à mon avis la meilleure car elle
concilie le mieux la liberté de chacun et les intérêts de tous.
Mais elle nécessite de bien avoir deux choses à l’esprit :

  - il n’existe pas pour un auteur de droit absolu de faire
    supprimer des propos tenus publiquement:

      - non seulement ce droit serait injuste pour d’autres

      - mais en plus l’argument n’est pas logique car si on admet
        un tel droit, alors il faut l’admettre à chacun ; or comme
        les messages publiés sont généralement publiés dans un
        contexte construit à plusieurs, il faut admettre qu’en
        définitive le message appartient un peu à plusieurs.

  - et que même si on veut admettre qu’il existe un tel droit, il
     y a de toute façon le choc de la réalité : à partir du moment
     où on a publié quelque chose, d’autant plus si on l’a publié
     par des moyens que l’on ne contrôle pas réellement (en
     passant par un service hébergé par un tiers par exemple),
     alors on perd nécessairement la totale maîtrise de son
     propos. Inutile de vouloir à tout prix censurer.

Finalement pour le moment, le problème se résout de lui-même par
les usages. C’est-à-dire que si Alice fait supprimer quelque
chose, même si cela cause un tort à Bob, il est possible que cela
soit minime et que donc, il ne réagisse pas (mais le problème est
que cela ne prend pas en compte les intérêts de tous, peut être
que *moi*, ça m’intéressait de comprendre ce qu’a dit Alice qui a
fait réagir Bob ainsi). Dans l’hypothèse où Alice tente de
supprimer quelque chose alors que cela a énormément d’impact, il
est probable que les utilisateurs aient pris des screenshots, ou que
des archives effectuées ailleurs resurgissent.
